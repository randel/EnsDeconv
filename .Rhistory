fit = coxph(Surv(T, event) ~ 1+x2+cluster(x3), data = df)
p = summary(fit)$coefficients[6]
return(p)
}
# Function to iterate the simulation. A data frame is returned.
n_sims = 5000
df <- replicate(n_sims, cluster_sim())
df <- as.data.frame(df)
names(df) <- c('p')
df <- df %>%
mutate(id = 1:n(),
param_caught = p < 0.05)
table(df$param_caught)
load("/Users/littleveg/Desktop/dtangle.data/data/abbas.rda")
View(abbas)
abbas[["annotation"]][["pure"]]
abbas[["annotation"]][["mixture"]]
?dtangle
library(dtangle)
?dtangle
abbas[["annotation"]][["pure_samples"]]
4^5
2^5
5/32-405/1024
((1+sqrt(5))/2)^32+((1-sqrt(5))/2)^32
vignette("TOAST")
library(readxl)
June_Aug_pt_list_1_ <- read_excel("Box/Kidney CHAMP/Education List/June-Aug pt list (1).xlsx")
View(June_Aug_pt_list_1_)
load("~/Box/KidneyCHAMP/Programs/Workdir/demo.RData")
View(dsDEMOGRAPHICS_all)
knitr::opts_chunk$set(echo = TRUE)
ds_eligibility3 <- read.csv(paste0(path.data_202104_xlsx,"/KidneyCHAMPPatientEl-EligibleAndEnrolledH_DATA_2021-05-04_1316.csv") ) %>% select(RECORD_ID = record_id,everything())
library(dplyr)
ds_eligibility3 <- read.csv(paste0(path.data_202104_xlsx,"/KidneyCHAMPPatientEl-EligibleAndEnrolledH_DATA_2021-05-04_1316.csv") ) %>% select(RECORD_ID = record_id,everything())
library(dplyr)
path.data_202104_xlsx <- "/Users/littleveg/Box/KidneyCHAMP/Data Sets and Data Documentation/20210422"
ds_eligibility3 <- read.csv(paste0(path.data_202104_xlsx,"/KidneyCHAMPPatientEl-EligibleAndEnrolledH_DATA_2021-05-04_1316.csv") ) %>% select(RECORD_ID = record_id,everything())
View(ds_eligibility3)
ds_eli = ds_eligibility3 %>% filter(medical_record_number_from %in% June_Aug_pt_list_1_$MRN)
View(ds_eli)
View(June_Aug_pt_list_1_)
setdiff(June_Aug_pt_list_1_$MRN,ds_eli$medical_record_number_from)
View(ds_eligibility3)
ds_demo = dsDEMOGRAPHICS_all %>% filter(RECORD_ID %in% ds_eli$RECORD_ID)
View(ds_demo)
8/3
install.packages("GA")
Rastrigin <- function(x1, x2)
{
20 + x1^2 + x2^2 - 10*(cos(2*pi*x1) + cos(2*pi*x2))
}
x1 <- x2 <- seq(-5.12, 5.12, by = 0.1)
f <- outer(x1, x2, Rastrigin)
persp3D(x1, x2, f, theta = 50, phi = 20, col.palette = bl2gr.colors)
filled.contour(x1, x2, f, color.palette = bl2gr.colors)
GA <- ga(type = "real-valued", fitness =  function(x) -Rastrigin(x[1], x[2]),
lower = c(-5.12, -5.12), upper = c(5.12, 5.12),
popSize = 50, maxiter = 100)
summary(GA)
plot(GA)
library(GA)
Rastrigin <- function(x1, x2)
{
20 + x1^2 + x2^2 - 10*(cos(2*pi*x1) + cos(2*pi*x2))
}
x1 <- x2 <- seq(-5.12, 5.12, by = 0.1)
f <- outer(x1, x2, Rastrigin)
persp3D(x1, x2, f, theta = 50, phi = 20, col.palette = bl2gr.colors)
filled.contour(x1, x2, f, color.palette = bl2gr.colors)
GA <- ga(type = "real-valued", fitness =  function(x) -Rastrigin(x[1], x[2]),
lower = c(-5.12, -5.12), upper = c(5.12, 5.12),
popSize = 50, maxiter = 100)
summary(GA)
plot(GA)
276/60
library(readr)
data <- read_csv("Desktop/10601/hw4/test/data.csv",
col_names = FALSE)
View(data)
knitr::opts_chunk$set(echo = TRUE)
rownames("model1_train","model1_valid","model2_train","model2_valid")
rownames(data) = c("model1_train","model1_valid","model2_train","model2_valid")
View(data)
data  = t(data)
View(data)
View(data)
data$epoch = 1:5000
View(data)
data <- read_csv("Desktop/10601/hw4/test/data.csv",
+     col_names = FALSE)
data <- read_csv("Desktop/10601/hw4/test/data.csv",  col_names = FALSE)
rownames(data) = c("model1_train","model1_valid","model2_train","model2_valid")
data  = t(data)
data = as.data.frame(data)
data$epoch = 1:5000
View(data)
test = gather(data, "model", "error", -epoch)
library(tidyr)
test = gather/(data, "model", "error", -epoch)
test = gather(data, "model", "error", -epoch)
View(test)
library(ggpubr)
summary(test)
library(dplyr)
library(stringr)
test %>% filter(str_detect(model,"model1")) %>%
ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
test %>% filter(str_detect(model,"model1")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "model", shape = "model",
color = "model", palette = c("#00AFBB", "#E7B800"))
test %>% filter(str_detect(model,"model2")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "model", shape = "model",
color = "model", palette = c("#00AFBB", "#E7B800"))
data <- read_csv("Desktop/10601/hw4/test/data.csv",  col_names = FALSE)
rownames(data) = c("model1_training","model1_validation","model2_training","model2_validation")
data  = t(data)
data = as.data.frame(data)
data$epoch = 1:5000
test = gather(data, "Data", "error", -epoch)
library(ggpubr)
test %>% filter(str_detect(model,"model1")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "model", shape = "model",
color = "model", palette = c("#00AFBB", "#E7B800"))
test %>% filter(str_detect(Data,"model1")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "Data", shape = "Data",
color = "Data", palette = c("#00AFBB", "#E7B800"))
test %>% filter(str_detect(Data,"model1")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "Data", shape = "Data",
color = "Data", palette = c("#00AFBB", "#E7B800"))
test %>% filter(str_detect(Data,"model2")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "Data", shape = "Data",
color = "Data", palette = c("#00AFBB", "#E7B800"))+ylab("Avg negative Log Likelihood")+xlab("Epochs")+title("Model 1")
test %>% filter(str_detect(Data,"model1")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "Data", shape = "Data",
color = "Data", palette = c("#00AFBB", "#E7B800"))+ylab("Avg negative Log Likelihood")+xlab("Epochs")
test %>% filter(str_detect(Data,"model2")) %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "Data", shape = "Data",
color = "Data", palette = c("#00AFBB", "#E7B800"))+ylab("Avg negative Log Likelihood")+xlab("Epochs")
library(readr)
data <- read_csv("Desktop/10601/hw4/test/data.csv",
col_names = FALSE)
View(data)
rownames(data) = c("alpha=0.01","alpha=0.1","alpha = 0.001")
data  = t(data)
data = as.data.frame(data)
data$epoch = 1:5000
test = gather(data, "alpha", "error", -epoch)
library(ggpubr)
test  %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "alpha", shape = "alpha",
color = "alpha")+ylab("Avg negative Log Likelihood")+xlab("Epochs")
data <- read_csv("Desktop/10601/hw4/test/data2.csv",  col_names = FALSE)
rownames(data) = c("alpha=0.1","alpha=0.01","alpha = 0.001")
data  = t(data)
data = as.data.frame(data)
data$epoch = 1:5000
test = gather(data, "alpha", "error", -epoch)
library(ggpubr)
test  %>%
#ggscatter(x="epoch", y = "error", color = "model")+geom_line(group = "model")
ggline(x="epoch", y = "error",
linetype = "alpha", shape = "alpha",
color = "alpha")+ylab("Avg negative Log Likelihood")+xlab("Epochs")
log(10)
1-0.2337
library(readxl)
KidneyCHAMPPatientEl_MTMReport_thru_4_22_21 <- read_excel("Desktop/Desktop - Little’s MacBook Pro/gsr/melanie/KidneyCHAMPPatientEl-MTMReport_thru 4-22-21.xlsx")
View(KidneyCHAMPPatientEl_MTMReport_thru_4_22_21)
library(scran)
?get_params
library(ggplot2)
library(plotly)
library(plyr)
library(flexdashboard)
library(tibble)
library(dplyr)
library(data.table)
library(tidyr)
library(tidyverse)
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/1026.RData")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/1026lab.RData")
#load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/1214_MACR.RData")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/1026_MACR.RData")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/0514_2.RData")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/0514_3.RData")
ds_pro_diag = readRDS("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/pro_diag1026.rds")
load("cr_onevalue.RData")
source("/Users/littleveg/Box/KidneyCHAMP/Programs/R functions/dataprep.R")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/pro_diag1026.RData")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/ds_egfr_1026.RData")
load("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/cr_1026.RData")
readRDS("t0_1110.rds")
readRDS("/Users/littleveg/Box/KidneyCHAMP/Programs/Workdir/t0_1110.rds")
library(pheatmap)
?pheatmap
test = matrix(rnorm(200), 20, 10)
test[1:10, seq(1, 10, 2)] = test[1:10, seq(1, 10, 2)] + 3
test[11:20, seq(2, 10, 2)] = test[11:20, seq(2, 10, 2)] + 2
test[15:20, seq(2, 10, 2)] = test[15:20, seq(2, 10, 2)] + 4
colnames(test) = paste("Test", 1:10, sep = "")
rownames(test) = paste("Gene", 1:20, sep = "")
# Draw heatmaps
pheatmap(test)
load("/Users/littleveg/Desktop/Desktop - Little’s MacBook Pro/research/11_08/heat.Rdata")
pheatmap(-log10(test_mtx3),cluster_rows = F,cluster_cols = F,na_col ="grey")
pheatmap(-log10(test_mtx3),annotation_row = test_annot,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90,na_col ="grey")
View(test_annot)
View(test_mtx3)
pheatmap(-log10(test_mtx3),annotation_row = test_annot,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90,na_col ="grey")
knitr::opts_chunk$set(echo = TRUE)
rownames(test_mtx3) <- paste0("row_", seq(nrow(test_mtx3)))
rownames(test_annot) <- paste0("row_", seq(nrow(test_annot)))
pheatmap(-log10(test_mtx3),annotation_row = test_annot,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90,na_col ="grey")
pheatmap(-log10(test_mtx3),,annotation_row = test_annot,annotation_colors = pheatmap_col,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90))
pheatmap(-log10(test_mtx3),,annotation_row = test_annot,annotation_colors = pheatmap_col,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90)
pheatmap(-log10(test_mtx3),,annotation_row = test_annot,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90)
pheatmap(-log10(test_mtx3),,annotation_row = test_annot,show_rownames=F,cluster_rows = F,cluster_cols = F,main = "-log10(p.value)",border_color = NA, treeheight_row = 0, treeheight_col = 0,fontsize = 9, angle_col = 90)
colnames(test_mtx3) = str_to_title(colnames(test_mtx3))
library(tidyverse)
library(stringr)
colnames(test_mtx3) = str_to_title(colnames(test_mtx3))
knitr::opts_chunk$set(echo = TRUE)
a = c(log(10),log(100),log(1000),log(10000))
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = cbind(a,Training,Validation)
View(data)
test = gather(data, "neglog", "data", -a)
library(reshape2)
data = as.data.frame(cbind(a,Training,Validation))
View(data)
test = gather(data, "neglog", "data", -a)
View(test)
test = gather(data, "data", "neglog", -a)
library(ggpubr)
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
data %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
test = gather(data, "data", "neglog", -a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
summary(test)
a = round(a,2)
a = c(log(10),log(100),log(1000),log(10000))
a = round(a,2)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+scale_x_log10()
a = c(10,100,1000,10000)
a = round(a,2)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+scale_x_log10()
a = c(10,100,1000,10000)
a = round(a,2)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+scale_x_continuous(trans='log')
a = c(10,100,1000,10000)
a = round(a,2)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test$a = as.numeric(a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+scale_x_continuous(trans='log')
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+scale_x_continuous(trans='log')
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
a = c(log(10),log(100),log(1000),log(10000))
a = round(a,2)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")
?scale_x_continuous
a = c(log(10),log(100),log(1000),log(10000))
a = round(a,2)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+ scale_x_continuous(labels=c(10,100,1000,10000))
test %>%
ggscatter(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg Log Likelihood")+xlab("Number of sequences used for training in log scale")+ scale_x_continuous(labels=c(10,100,1000,10000))
test %>%
ggline(x="a", y = "neglog",
linetype = "data", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_discrete(labels = c(10,100,1000,10000))
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_discrete(labels = c("10","100","1000","10000"))
a = c(10,100,1000,10000)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_log10()
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_discrete(trans = "log")
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_continuous(trans = "log")
a = c(10,100,1000,10000)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_continuous(trans = "log")
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_continuous(trans = "log",breaks = c(10,100,1000,10000))
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")
a = c(10,100,1000,10000)
Training = c(-80.54472148949841,-74.99444935893663,-67.59317395746378,-60.61228444225903)
Validation = c(-87.97153090660595,-80.83229271827628,-70.45566558750289,-61.08562092334479)
data = as.data.frame(cbind(a,Training,Validation))
test = gather(data, "data", "neglog", -a)
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")
test %>%
ggscatter(x="a", y = "neglog", shape = "data",
color = "data")+ylab("Avg negative Log Likelihood")+xlab("Number of sequences used for traning")+scale_x_continuous(trans = "log",breaks = c(10,100,1000,10000))
0.8*0.18
-0.4+0.01*(-1.4)
-0.4+0.01*(-1+0.4)
for (i in 1:1000) {
xi = x+0.01*(-1-x)
x = xi
}
x = -0.406
for (i in 1:1000) {
xi = x+0.01*(-1-x)
x = xi
}
x = 0.5
for (i in 1:1000) {
xi = x+0.01*(0+1-x)
x = xi
}
160*192
x = -0.4
for (i in 1:1000) {
xi = x+0.01*(-1-x)
x = xi
}
x = -0.4
for (i in 1:10000) {
xi = x+0.01*(-1-x)
x = xi
}
4^6
setwd("~/Documents/GitHub/test")
setwd("~/Documents/GitHub/EnsDeconv")
library(pkgdown)
build_site()
build_site()
get_os <- function(){
sysinf <- Sys.info()
if (!is.null(sysinf)){
os <- sysinf['sysname']
if (os == 'Darwin')
os <- "osx"
} else { ## mystery machine
os <- .Platform$OS.type
if (grepl("^darwin", R.version$os))
os <- "osx"
if (grepl("linux-gnu", R.version$os))
os <- "linux"
}
tolower(os)
}
get_os()
Sys.info()['sysname']
Sys.info()
test = Sys.info()
Sys.info()[1]
Sys.info()['sysname']
.Platform$OS.type
get_os <- function(){
os_type =.Platform$OS.type
if(os_type == "unix"){
sysinf <- Sys.info()
if (!is.null(sysinf)){
os <- sysinf['sysname']
if (os == 'Darwin')
os <- "osx"
} else { ## mystery machine
os <- .Platform$OS.type
if (grepl("^darwin", R.version$os))
os <- "osx"
if (grepl("linux-gnu", R.version$os))
os <- "linux"
}
tolower(os)
}else{
os = os_type
}
return(os)
}
get_os()
library(devtools)
install_github("randel/EnsDeconv",dependencies = T)
library(pkgdown)
build_site()
install_github("randel/EnsDeconv",dependencies = T)
build_site()
load("~/Documents/GitHub/EnsDeconv/data/testdata.RData")
testdata$count_bulk = testdata$count_bulk+1
View(testdata)
testdata$meta_bulk = NULL
setwd("~/Documents/GitHub/EnsDeconv/data")
save(testdata, file = "testdata.RData")
rm(testdata)
install_github("randel/EnsDeconv",dependencies = T)
library(EnsDeconv)
testdata= EnsDeconv::testdata
View(testdata)
getwd()
testdata$meta_bulk = NULL
tdata= EnsDeconv::testdata
save(testdata, file = "testdata.RData")
remotes::install_url("https://gjhunt.github.io/hspe/hspe_0.1.tar.gz")
setwd("~/Documents/GitHub/EnsDeconv")
use_mit_license()
build_site()
build_site()
a = c(-0.7716752,-0.8318270,-0.4911101,-0.6783492,-0.7906973)
scale(a)
